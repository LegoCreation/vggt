defaults:
  - default_dataset.yaml

exp_name: nvs_training
img_size: 28 
patch_size: 14
max_epochs: 100
num_workers: 8
seed_value: 42
accum_steps: 64

data:
  train:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: True
      repeat_batch: True
      training: True
      get_nearby: True
      inside_random: True
      allow_duplicate_img: False
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        - _target_: data.datasets.nvs.NVSDataset
          split: train
          DATA_DIR: /storage/slurm/lavingal/lavingal/LVSM/datasets/re10k/train
  val:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: True
      training: False
      get_nearby: True
      inside_random: True
      allow_duplicate_img: False
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        - _target_: data.datasets.nvs.NVSDataset
          split: test
          DATA_DIR: /storage/slurm/lavingal/lavingal/LVSM/datasets/re10k/train

logging:
  log_dir: logs
  log_visuals: True
  log_freq: 50
  log_level_primary: DEBUG
  log_level_secondary: WARNING
  all_ranks: False
  tensorboard_writer:
    _target_: train_utils.tb_writer.TensorBoardLogger
    path: ${logging.log_dir}/tensorboard
  wandb:
    _target_: train_utils.wandb_logger.WandbLogger
    project: VGGT_nvs
    name: ${exp_name}
    log_freq: 50

checkpoint:
  save_dir: logs/${exp_name}/ckpts
  save_freq: 5
  resume_checkpoint_path: null
  strict: False

loss:
  _target_: loss.MultitaskLoss
  camera: 
    weight: 0.0
  depth:
    weight: 0.0
  point: null
  track: null
  nvs:
    weight: 1.0
    conf_weight: 0.1

model:
  _target_: vggt.models.vggt.VGGT
  img_size: ${img_size}
  patch_size: ${patch_size}
  embed_dim: 1024

optim:
  param_group_modifiers: False
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.00001
    weight_decay: 0.05
  frozen_module_names:
    - "*aggregator*"
  amp:
    enabled: True
    amp_dtype: bfloat16
  gradient_clip:
    _target_: train_utils.gradient_clip.GradientClipper
    configs:
      - module_name: ["aggregator.patch_embed"]
        max_norm: 1.0
        norm_type: 2
      - module_name: ["aggregator.frame_blocks"]
        max_norm: 1.0
        norm_type: 2
      - module_name: ["aggregator.global_blocks"]
        max_norm: 1.0
        norm_type: 2
      - module_name: ["aggregator.target_view_embed"]
        max_norm: 1.0
        norm_type: 2
      - module_name: ["aggregator.camera_token", "aggregator.register_token"]
        max_norm: 1.0
        norm_type: 2
      - module_name: ["nvs_head"]
        max_norm: 1.0
        norm_type: 2
  options:
    lr:
      - scheduler:
          _target_: fvcore.common.param_scheduler.CompositeParamScheduler
          schedulers:
            - _target_: fvcore.common.param_scheduler.LinearParamScheduler
              start_value: 1e-8
              end_value: 0.00001
            - _target_: fvcore.common.param_scheduler.CosineParamScheduler
              start_value: 0.00001
              end_value: 1e-8
          lengths: [0.05, 0.95]
          interval_scaling: ['rescaled', 'rescaled']
    weight_decay:
      - scheduler:
          _target_: fvcore.common.param_scheduler.ConstantParamScheduler
          value: 0.05

distributed:
  backend: nccl
  comms_dtype: None
  find_unused_parameters: False
  timeout_mins: 30
  gradient_as_bucket_view: True
  bucket_cap_mb: 25
  broadcast_buffers: True

cuda:
  cudnn_deterministic: False
  cudnn_benchmark: False
  allow_tf32: True 